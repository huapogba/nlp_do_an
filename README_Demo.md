# LongEmbed â€“ Demo Retrieval vá»›i Long Document Embeddings

ğŸ’¡ **Má»¥c tiÃªu demo:** thá»­ nghiá»‡m kháº£ nÄƒng má»Ÿ rá»™ng embedding cho mÃ´ hÃ¬nh E5 trong cÃ¡c tÃ¡c vá»¥ truy xuáº¥t thÃ´ng tin (retrieval) trÃªn vÄƒn báº£n dÃ i, khÃ´ng cáº§n huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh â€“ chá»‰ thay Ä‘á»•i positional embedding.

---

## ğŸš€ 1. Giá»›i thiá»‡u
Trong NLP, nhiá»u tÃ¡c vá»¥ yÃªu cáº§u mÃ´ hÃ¬nh Ä‘á»c vÃ  tÃ¬m kiáº¿m thÃ´ng tin tá»« vÄƒn báº£n ráº¥t dÃ i. Tuy nhiÃªn, Ä‘a sá»‘ embedding models chá»‰ há»— trá»£ ~512 token, gÃ¢y giá»›i háº¡n kháº£ nÄƒng truy xuáº¥t.

**Long Embedding (LongEmbed)** giÃºp má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh lÃªn Ä‘áº¿n 4kâ€“32k tokens, tá»« Ä‘Ã³ cáº£i thiá»‡n kháº£ nÄƒng tÃ¬m kiáº¿m Ä‘oáº¡n vÄƒn liÃªn quan.

Demo nÃ y táº­p trung thá»­ nghiá»‡m mÃ´ hÃ¬nh **E5-Base-4k**, so sÃ¡nh káº¿t quáº£ retrieval trÆ°á»›c vÃ  sau khi má»Ÿ rá»™ng positional embedding.

---

## ğŸ“¦ 2. Bá»™ dá»¯ liá»‡u sá»­ dá»¥ng
Demo sá»­ dá»¥ng 2 synthetic datasets tá»« benchmark LongEmbed:

| Dataset | MÃ´ táº£ | ThÃ nh pháº§n |
|---------|-------|------------|
| **LEMBNeedleRetrieval** | Document chá»©a thÃ´ng tin nhá»/hiáº¿m ("needle") | Corpus / Queries / Qrels |
| **LEMBPasskeyRetrieval** | Document chá»©a passkey cáº§n truy xuáº¥t chÃ­nh xÃ¡c | Corpus / Queries / Qrels |

ğŸ“Œ Synthetic dataset giÃºp mÃ´ phá»ng mÃ´i trÆ°á»ng vÄƒn báº£n dÃ i vá»›i kháº£ nÄƒng Ä‘iá»u chá»‰nh Ä‘á»™ dÃ i document.

---

## ğŸ§  3. MÃ´ hÃ¬nh sá»­ dá»¥ng
| Model | MÃ´ táº£ |
|-------|------|
| **E5-Base-4k** | Má»Ÿ rá»™ng embedding lÃªn 4.096 position IDs |
| **E5-RoPE-Base** | KhÃ´ng cháº¡y trong demo do giá»›i háº¡n tÃ i nguyÃªn |

---

## ğŸ§ª 4. CÃ¡ch cÃ i Ä‘áº·t & cháº¡y demo

### CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
```bash
git clone https://github.com/dwzhu-pku/LongEmbed.git
cd LongEmbed
pip install -r requirements.txt
```

### Táº£i dá»¯ liá»‡u
```python
from datasets import load_dataset
needle = load_dataset("dwzhu/LongEmbed", name="needle", split="corpus")
passkey = load_dataset("dwzhu/LongEmbed", name="passkey", split="corpus")
```

### Cháº¡y Ä‘Ã¡nh giÃ¡
```python
from mteb import MTEB
eval = MTEB(tasks=["LEMBNeedleRetrieval","LEMBPasskeyRetrieval"])
eval.run(model)
```

---

## ğŸ“Š 5. Káº¿t quáº£ Demo
ğŸ“Œ ÄÃ¡nh giÃ¡ dá»±a trÃªn NDCG, MAP, Recall, MRR, Precision

### ğŸ”¹ Needle Retrieval â€“ 1024 token
| Metric | @1 | @5 | @10 | @100 | @1000 |
|--------|----|----|-----|------|-------|
| Cháº¡y bÃ¬nh thÆ°á»ng | 0.66 | 0.80 | 0.82 | 0.83 | 0.83 |
| Má»Ÿ rá»™ng embedding | **0.70** | **0.82** | **0.84** | **0.85** | **0.85** |

### ğŸ”¹ Passkey Retrieval â€“ 512 token
| Metric | @1 | @5 | @10 | @100 | @1000 |
|--------|----|----|-----|------|-------|
| Cháº¡y bÃ¬nh thÆ°á»ng | 0.70 | 0.85 | 0.86 | 0.86 | 0.86 |
| Má»Ÿ rá»™ng embedding | **1.00** | **1.00** | **1.00** | **1.00** | **1.00** |

ğŸ“Œ Nháº­n xÃ©t nhanh:  
- Long embedding cáº£i thiá»‡n hiá»‡u quáº£ retrieval Ä‘Ã¡ng ká»ƒ  
- Vá»›i Passkey Retrieval, káº¿t quáº£ Ä‘áº¡t **100%** toÃ n bá»™ top-k  

---

## ğŸ 6. Káº¿t luáº­n
- Long embedding giÃºp mÃ´ hÃ¬nh duy trÃ¬ kháº£ nÄƒng biá»ƒu diá»…n trÃªn vÄƒn báº£n dÃ i
- KhÃ´ng thay Ä‘á»•i kiáº¿n trÃºc mÃ´ hÃ¬nh â€“ chá»‰ cáº£i thiá»‡n positional encoding
- Hiá»‡u quáº£ Ä‘áº·c biá»‡t máº¡nh Ä‘á»‘i vá»›i bÃ i toÃ¡n chá»©a thÃ´ng tin "áº©n sÃ¢u" (passkey)

---

## ğŸ“š Tham kháº£o
LongEmbed â€“ Extending Embedding Models for Long Context Retrieval â€“ arXiv:2404.12096
